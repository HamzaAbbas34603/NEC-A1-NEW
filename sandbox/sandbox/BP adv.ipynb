{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNetwork:            \n",
    "    def __init__(self, layers, learning_rate, momentum, activation, validation_percentage=0):\n",
    "        self.L = len(layers)\n",
    "        self.n = layers.copy()\n",
    "        self.xi = [np.zeros(l) for l in layers]\n",
    "        self.w = [np.random.randn(layers[i], layers[i-1]) for i in range(1, self.L)]\n",
    "        self.theta = [np.zeros(l) for l in layers]\n",
    "        self.delta = [np.zeros(l) for l in layers]\n",
    "        self.d_w = [np.zeros_like(w) for w in self.w]\n",
    "        self.d_theta = [np.zeros_like(t) for t in self.theta]\n",
    "        self.d_w_prev = [np.zeros_like(w) for w in self.w]\n",
    "        self.d_theta_prev = [np.zeros_like(t) for t in self.theta]\n",
    "        self.learning_rate = learning_rate \n",
    "        self.momentum = momentum \n",
    "        self.activation = activation\n",
    "        self.validation_percentage = validation_percentage\n",
    "        self.loss_epochs = []\n",
    "\n",
    "    def activation_function(self, x):\n",
    "        if self.activation == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        elif self.activation == 'relu':\n",
    "            return np.maximum(0, x)\n",
    "        elif self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'tanh':\n",
    "            return np.tanh(x)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid activation function\")\n",
    "\n",
    "    def activation_derivative(self, x):\n",
    "        if self.activation == 'sigmoid':\n",
    "            return x * (1 - x)\n",
    "        elif self.activation == 'relu':\n",
    "            return np.where(x > 0, 1, 0)\n",
    "        elif self.activation == 'linear':\n",
    "            return 1\n",
    "        elif self.activation == 'tanh':\n",
    "            return 1 - x**2\n",
    "        else:\n",
    "            raise ValueError(\"Invalid activation function\")\n",
    "\n",
    "    def forward_pass(self, x):\n",
    "        self.xi[0] = x\n",
    "        for i in range(1, self.L):\n",
    "            self.xi[i] = self.activation_function(np.dot(self.w[i-1], self.xi[i-1]) - self.theta[i])\n",
    "\n",
    "    def backward_pass(self, y):\n",
    "        self.delta[-1] = (self.xi[-1] - y) * self.activation_derivative(self.xi[-1])\n",
    "        for i in range(self.L - 2, 0, -1):\n",
    "            self.delta[i] = np.dot(self.w[i].T, self.delta[i+1]) * self.activation_derivative(self.xi[i])\n",
    "\n",
    "    def update_weights(self):\n",
    "        for i in range(1, self.L):\n",
    "            self.d_w[i-1] = self.learning_rate * np.outer(self.delta[i], self.xi[i-1]) + self.momentum * self.d_w_prev[i-1]\n",
    "            self.d_theta[i] = self.learning_rate * self.delta[i] + self.momentum * self.d_theta_prev[i]\n",
    "            self.w[i-1] -= self.d_w[i-1]\n",
    "            self.theta[i] -= self.d_theta[i]\n",
    "            self.d_w_prev[i-1] = self.d_w[i-1]\n",
    "            self.d_theta_prev[i] = self.d_theta[i]\n",
    "            \n",
    "    def mape(self, y_true, y_pred):\n",
    "        mask = y_true != 0\n",
    "        return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "    def fit(self, X, y, epochs, batch_size=32, learning_rate_decay=0.1):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=self.validation_percentage, random_state=42)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for _ in range(0, len(X_train), batch_size):\n",
    "                batch_indices = np.random.choice(len(X_train), min(batch_size, len(X_train)), replace=False)\n",
    "                if len(batch_indices) < 2:  # Skip batches with less than 2 samples\n",
    "                    continue\n",
    "\n",
    "                X_batch, y_batch = X_train[batch_indices], y_train[batch_indices]\n",
    "\n",
    "                for i in range(len(X_batch)):\n",
    "                    x_sample, y_sample = X_batch[i], y_batch[i]\n",
    "                    self.forward_pass(x_sample)\n",
    "                    self.backward_pass(y_sample)\n",
    "                    self.update_weights()\n",
    "\n",
    "            # Calculate metrics with safeguards\n",
    "            train_predictions = self.predict(X_train)\n",
    "            val_predictions = self.predict(X_val)\n",
    "\n",
    "            training_error = mean_squared_error(y_train, train_predictions)\n",
    "            validation_error = mean_squared_error(y_val, val_predictions)\n",
    "\n",
    "            training_r2 = r2_score(y_train, train_predictions) if len(y_train) > 1 else None\n",
    "            validation_r2 = r2_score(y_val, val_predictions) if len(y_val) > 1 else None\n",
    "\n",
    "            print(f\"Epoch {epoch}/{epochs} - Training Error: {training_error}, Validation Error: {validation_error}, Training R2: {training_r2}, Validation R2: {validation_r2}\")\n",
    "\n",
    "            # Learning rate decay\n",
    "            self.learning_rate *= (1.0 / (1.0 + learning_rate_decay * epoch))\n",
    "\n",
    "        final_train_mape = self.mape(y_train, self.predict(X_train))\n",
    "        final_val_mape = self.mape(y_val, self.predict(X_val))\n",
    "        final_train_r2 = r2_score(y_train, self.predict(X_train))\n",
    "        final_val_r2 = r2_score(y_val, self.predict(X_val))\n",
    "        print(f\"Final Training MAPE: {final_train_mape}, Final Validation MAPE: {final_val_mape}\")\n",
    "        print(f\"Final Training R2: {final_train_r2}\")\n",
    "        print(f\"Final Training MSE: {training_error}, Final Validation MSE: {validation_error}\")\n",
    "        return np.array(self.loss_epochs)\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for i in range(len(X)):\n",
    "            self.forward_pass(X[i])\n",
    "            predictions.append(self.xi[-1][0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def get_loss_epochs(self):\n",
    "        return np.array(self.loss_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "# Load the Boston Housing dataset\n",
    "adverstiment_data = 'Preprocessed/preprocessed_Adversting_data.csv'\n",
    "adverstiment_data = pd.read_csv(adverstiment_data, skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Daily Time Spent on Site</th>\n",
       "      <th>Age</th>\n",
       "      <th>Area Income</th>\n",
       "      <th>Daily Internet Usage</th>\n",
       "      <th>Male</th>\n",
       "      <th>Clicked on Ad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.617882</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.730472</td>\n",
       "      <td>0.916031</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.809621</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.831375</td>\n",
       "      <td>0.538746</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.626721</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.699200</td>\n",
       "      <td>0.797433</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.706272</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.623160</td>\n",
       "      <td>0.854280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.608023</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.914568</td>\n",
       "      <td>0.731323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Daily Time Spent on Site       Age  Area Income  Daily Internet Usage  \\\n",
       "0                  0.617882  0.380952     0.730472              0.916031   \n",
       "1                  0.809621  0.285714     0.831375              0.538746   \n",
       "2                  0.626721  0.166667     0.699200              0.797433   \n",
       "3                  0.706272  0.238095     0.623160              0.854280   \n",
       "4                  0.608023  0.380952     0.914568              0.731323   \n",
       "\n",
       "   Male  Clicked on Ad  \n",
       "0     0              0  \n",
       "1     1              0  \n",
       "2     0              0  \n",
       "3     1              0  \n",
       "4     0              0  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adverstiment_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 6 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Daily Time Spent on Site  1000 non-null   float64\n",
      " 1   Age                       1000 non-null   float64\n",
      " 2   Area Income               1000 non-null   float64\n",
      " 3   Daily Internet Usage      1000 non-null   float64\n",
      " 4   Male                      1000 non-null   int64  \n",
      " 5   Clicked on Ad             1000 non-null   int64  \n",
      "dtypes: float64(4), int64(2)\n",
      "memory usage: 47.0 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Daily Time Spent on Site</th>\n",
       "      <th>Age</th>\n",
       "      <th>Area Income</th>\n",
       "      <th>Daily Internet Usage</th>\n",
       "      <th>Male</th>\n",
       "      <th>Clicked on Ad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.550743</td>\n",
       "      <td>0.404976</td>\n",
       "      <td>0.626119</td>\n",
       "      <td>0.455383</td>\n",
       "      <td>0.481000</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.269482</td>\n",
       "      <td>0.209180</td>\n",
       "      <td>0.204840</td>\n",
       "      <td>0.265785</td>\n",
       "      <td>0.499889</td>\n",
       "      <td>0.50025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.318885</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.504446</td>\n",
       "      <td>0.206139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.605388</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.656847</td>\n",
       "      <td>0.474331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.781022</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.786005</td>\n",
       "      <td>0.690232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Daily Time Spent on Site          Age  Area Income  \\\n",
       "count               1000.000000  1000.000000  1000.000000   \n",
       "mean                   0.550743     0.404976     0.626119   \n",
       "std                    0.269482     0.209180     0.204840   \n",
       "min                    0.000000     0.000000     0.000000   \n",
       "25%                    0.318885     0.238095     0.504446   \n",
       "50%                    0.605388     0.380952     0.656847   \n",
       "75%                    0.781022     0.547619     0.786005   \n",
       "max                    1.000000     1.000000     1.000000   \n",
       "\n",
       "       Daily Internet Usage         Male  Clicked on Ad  \n",
       "count           1000.000000  1000.000000     1000.00000  \n",
       "mean               0.455383     0.481000        0.50000  \n",
       "std                0.265785     0.499889        0.50025  \n",
       "min                0.000000     0.000000        0.00000  \n",
       "25%                0.206139     0.000000        0.00000  \n",
       "50%                0.474331     0.000000        0.50000  \n",
       "75%                0.690232     1.000000        1.00000  \n",
       "max                1.000000     1.000000        1.00000  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adverstiment_data.info()\n",
    "\n",
    "adverstiment_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (X) and target variable (y)\n",
    "X = adverstiment_data.drop('Clicked on Ad', axis=1)\n",
    "y = adverstiment_data['Clicked on Ad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network parameters with two hidden layers\n",
    "layers = [6, 9, 15, 1]  # Input layer: 13 features, Hidden layers: 10, 8, Output layer: 1 unit\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "activation = 'sigmoid'\n",
    "validation_percentage = 0.2\n",
    "epochs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([761, 202, 727, 646, 708,  70, 600, 481, 791, 697, 750, 117, 741, 145,\\n       257, 369, 194, 690, 408, 419, 733, 169, 655, 594, 458, 450, 135, 244,\\n       500, 121,  74, 444],\\n      dtype='int32')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create and train the neural network\u001b[39;00m\n\u001b[0;32m      2\u001b[0m nn \u001b[38;5;241m=\u001b[39m MyNeuralNetwork(layers, learning_rate, momentum, activation, validation_percentage)\n\u001b[1;32m----> 3\u001b[0m loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[72], line 75\u001b[0m, in \u001b[0;36mMyNeuralNetwork.fit\u001b[1;34m(self, X, y, epochs, batch_size, learning_rate_decay)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch_indices) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:  \u001b[38;5;66;03m# Skip batches with less than 2 samples\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m X_batch, y_batch \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_indices\u001b[49m\u001b[43m]\u001b[49m, y_train[batch_indices]\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_batch)):\n\u001b[0;32m     78\u001b[0m     x_sample, y_sample \u001b[38;5;241m=\u001b[39m X_batch[i], y_batch[i]\n",
      "File \u001b[1;32mc:\\Users\\pranj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\pranj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pranj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([761, 202, 727, 646, 708,  70, 600, 481, 791, 697, 750, 117, 741, 145,\\n       257, 369, 194, 690, 408, 419, 733, 169, 655, 594, 458, 450, 135, 244,\\n       500, 121,  74, 444],\\n      dtype='int32')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Create and train the neural network\n",
    "nn = MyNeuralNetwork(layers, learning_rate, momentum, activation, validation_percentage)\n",
    "loss_history = nn.fit(X, y, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
